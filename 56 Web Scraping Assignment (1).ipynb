{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5074fb2d",
   "metadata": {},
   "source": [
    "by Amarah Iqbal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c929d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355b7103",
   "metadata": {},
   "source": [
    "Web scraping is the process of extracting data from websites programmatically.\n",
    "It involves using automated tools and scripts to gather data from web pages and convert it into a structured format, such as a CSV file or a database.\n",
    "\n",
    "Web scraping is used for a variety of purposes, including:\n",
    "\n",
    "Market research: Web scraping can be used to gather data on competitor pricing, product features, and customer reviews, which can be used to inform marketing and product development decisions.\n",
    "\n",
    "Academic research: Web scraping can be used to gather data for academic research, such as sentiment analysis of online news articles or social media posts.\n",
    "\n",
    "Business intelligence: Web scraping can be used to gather data on industry trends, consumer behavior, and other business-related information, which can be used to inform strategic decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed00d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a9443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "There are several methods used for web scraping, including:\n",
    "\n",
    "Manual scraping: This involves manually copying and pasting data from web pages into\n",
    "    a spreadsheet or other format.\n",
    "\n",
    "Web scraping software: This involves using software tools, such as web scrapers, to automatically\n",
    "    extract data from web pages.\n",
    "\n",
    "Application programming interfaces (APIs): Some websites offer APIs that allow developers\n",
    "    to access data in a structured format without the need for web scraping.\n",
    "\n",
    "Browser extensions: These are tools that can be added to a web browser to enable web scraping\n",
    "    functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a91e2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f413434d",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library used for web scraping purposes.\n",
    "\n",
    "It is used to parse HTML and XML documents, making it easier to extract data from web pages.\n",
    "\n",
    "Beautiful Soup provides a simple and intuitive way to navigate and search the document tree,\n",
    "which can be especially useful for scraping data from websites that have complex page structures. Beautiful Soup also provides methods for data extraction and manipulation, such as filtering and formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc5b32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6867d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Flask is a web framework for Python that is used for developing web applications. \n",
    "Flask was likely used in this web scraping project because it provides a simple and \n",
    "lightweight way to build web applications.\n",
    "Flask allows developers to easily create routes\n",
    "and views, handle HTTP requests and responses, and integrate with other Python libraries and tools.\n",
    "Flask is also highly customizable,\n",
    "making it a popular choice for building web applications of varying complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5628f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f2b8b",
   "metadata": {},
   "source": [
    "AWS services used for web scraping project include:\n",
    "\n",
    "Elastic Beanstalk- is a service for deploying and managing web applications and servicese\n",
    "\n",
    "\n",
    "CodePipeline-  is a service for automating your software release process. Both services are designed to simplify the deployment and release of your applications and services on AWS.\n",
    "\n",
    "\n",
    "Pymongo and Git from Flask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8b6142",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
